{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to a file and creation of embedding in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"stort.txt\",'r')\n",
    "text = file.readlines()\n",
    "file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(text):\n",
    "    word=''\n",
    "    sentence=''\n",
    "    paragraph=[]\n",
    "    for row in text:\n",
    "        for char in row:\n",
    "            if char !=' ':\n",
    "                word=word+char\n",
    "                #print(word)\n",
    "            else:\n",
    "                sentence=sentence+word\n",
    "                #print(sentence)\n",
    "                word=' '\n",
    "            if len(sentence.split())==100:\n",
    "                #print(sentence)\n",
    "                paragraph.append(sentence)\n",
    "                sentence=' '\n",
    "\n",
    "    return paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = text_split(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1039,  1005,  3690, 14477, 26089, 14477, 17768, 10936,  4143,\n",
      "          4487,  2053,  4168, 15669, 18719,  2050,  1010,  6335, 12731,  2072,\n",
      "          2061, 18752,  6499, 13642,  3567,  2474,  6178,  6305,  6590,  4487,\n",
      "          5665, 12717, 26148,  6335, 12256,  3527,  6970,  2080,  1012, 13642,\n",
      "          3567, 11192,  4048,  4880,  6894,  3459,  7088, 18178,  4907,  4143,\n",
      "          6212,  2080,  9530,  6335, 18834,  2080,  1041,  1051, 25955,  3609,\n",
      "          2053, 14693,  6030, 18178,  7367, 14905,  2527,  6212,  2080,  9530,\n",
      "          6528,  7869, 10722,  4674,  3393, 15544, 13102, 14122,  2063,  2035,\n",
      "          2063, 14383,  5685,  2063, 24624, 27904, 11268, 15422,  2063,  8611,\n",
      "         19300,  1012, 15669, 18719,  2050,  2512,  3690,  3948, 12101,  1025,\n",
      "         13642,  3567,  4895, 12731,  5686,  8991, 15286,  1041, 14477,  2273,\n",
      "          2618,  7987,  9386, 10111,  1010,  7367,  8737,  2890,  4013, 12380,\n",
      "          1037,  8292, 18992,  2890,  2474,  9852, 20715,   102]])\n",
      "tensor([[  101,  4066,  2063,  1010,  2512, 15544,  2271,  6895,  6767,  1037,\n",
      "          4190,  4590,  2063,  1012, 26947,  3413,  2050, 10701,  4487,  2474,\n",
      "         29655,  1010,  9530,  4895,  6187, 26745, 25226,  2632, 26458, 16786,\n",
      "         29480,  1010,  1041,  2566,  4895, 21541, 12956,  6335, 13657,  7367,\n",
      "         14905,  2527, 10701, 10768, 17830,  2869,  2072,  1012,  6335, 10514,\n",
      "          2080,  2061, 18752,  6499,  3690,  4895, 17768, 11411,  4487, 19913,\n",
      "         18178,  2771,  4937, 27431, 10701,  2035,  1005, 21541, 12956,  1012,\n",
      "         15669, 18719,  2050,  2771,  3457,  2050, 10701,  1041,  1010,  2005,\n",
      "          3366,  2566,  8991, 15286, 20715,  1010,  2771, 16183, 13210, 10701,\n",
      "          9530,  4895,  8292, 10695,  2080,  1012, 11865,  7182,  2063,  2566,\n",
      "          3888,  2072,  6178,  7442, 18178, 13642,  6767, 10439,  8189,  4297,\n",
      "         12162,  8609,  2080, 24209,  2389, 10841,  3630,  4487,  2569,  2063,\n",
      "          1012, 11265,  2072, 21025,  9691,  2072, 18178,   102]])\n",
      "tensor([[  101,  4487,  2512,  7367, 14905, 19848,  2063, 19817,  7361,  6873,\n",
      "         11265,  2099, 19862,  2080,  1012, 26947,  2632,  4143, 10701,  8840,\n",
      "         22214,  6692, 20683,  1041,  2771, 21279,  2050, 10701,  4895,  2061,\n",
      "         18752,  6499,  2522,  3736, 29655, 10250,  3527, 18178,  7367, 14905,\n",
      "          2527,  3567, 16596,  8649, 14355,  2063, 13958,  3490,  2019,  8464,\n",
      "          1012,  4830, 10861,  2140,  2617,  2080,  1010,  3393, 16839,  7913,\n",
      "          6819,  2618,  1999, 10993,  2401,  4948,  2080,  1037, 20014,  2890,\n",
      "         14693, 11650,  2072,  2272,  1045,  8223,  2072,  4487, 10861,  3363,\n",
      "          1005,  2632,  5677,  2080,  2061,  9284, 12731,  2072, 25022,  3690,\n",
      "          3567,  5302,  4297, 12162,  8609,  2072,  1012, 15669, 18719,  2050,\n",
      "          3690, 11345,  2532,  4487,  6896,  2072,  1024, 25933,  3567, 16510,\n",
      "          9912,  2063, 12517, 12162,  2072,  1010,  2064,  7559,  2063,  2064,\n",
      "         11597,  2072,  2061,  9284,  2474, 14255,  8649,   102]])\n",
      "tensor([[  101,  8292, 16643,  3630,  4830, 12695,  1012,  6335, 25022, 18349,\n",
      "          9033,  3690,  9543,  3406,  4487, 19027, 12273,  3258,  2063,  1041,\n",
      "         10482,  1010,  1041,  6335, 18834,  2080,  3417, 12462,  9530,  7842,\n",
      "         29652,  6335, 11268,  2819,  2080, 14866, 10882, 10050,  9765, 12848,\n",
      "          2072,  1012, 15669, 18719,  2050,  3457, 12462,  1048,  1005,  2030,\n",
      "         10993, 11597,  2618,  9530, 14477, 19913, 11265, 25394,  1051, 25955,\n",
      "         18178,  7367, 14905,  2527,  3567, 10958, 21408, 12380,  2890,  4971,\n",
      "          2063,  2358, 10050,  2063,  1012,  1000, 18952,  1010,  1000,  4487,\n",
      "         11393,  2035,  1005, 17727, 12298, 11365,  2080,  1010,  1000,  1037,\n",
      "          5285,  2618, 25636,  2080, 18178, 25583,  2080, 21864,  2566,  6819,\n",
      "         28943, 13958,  3490,  6170, 12898,  2617,  2080,  9530, 10722,  5946,\n",
      "          1048,  1005,  2019,  9581,  1012,  2512, 12324,  2050, 24110,  3406,\n",
      "          9026,  1051, 29368,  9033,  2050,  1012,  1000,   102]])\n",
      "tensor([[  101, 10958, 21408, 13663,  1012,  6335, 13657,  3413, 12462,  1010,\n",
      "          1041,  6335, 16839, 13181,  4190, 14074, 11529, 12380,  3567,  7367,\n",
      "          8737,  2890, 24624, 27904, 24898,  1012, 11113, 11607,  5302, 21358,\n",
      "         12792, 10610, 16021,  2666,  4168,  3393,  4487, 26989, 25778,  2696,\n",
      "          1010, 15544,  6499, 10346,  2080,  2035,  2063, 18749, 20026,  2063,\n",
      "          1010,  1041,  3465,  6820,  9956,  7043, 17080, 18178,  8716,  6633,\n",
      "          2080,  7367,  8737,  2890, 11265,  2140, 12731,  5686,  1012, 15669,\n",
      "         18719,  2050,  2512,  3690,  3948,  2474,  8764,  4012,  4502, 16989,\n",
      "          1025,  3690,  2474,  8764, 23154,  1010,  2474,  8764,  2005,  4143,\n",
      "          1010,  1041,  2474,  8764, 19117, 12798,  2890, 26445,  3540,  1012,\n",
      "          9530, 26947,  1010,  7570, 17727, 25879,  2080, 18178,  1048,  1005,\n",
      "         26297,  2512,  1037, 29651,  3948,  4895, 15792,  2080,  1010,  5003,\n",
      "         14477,  8040, 20042,  2050, 22035,  3775, 11692,   102]])\n"
     ]
    }
   ],
   "source": [
    "def embedding_text(text):\n",
    "    encoding = tokenizer.batch_encode_plus([text],\n",
    "                padding='max_length',\n",
    "                max_length=128,\n",
    "                truncation=True,\n",
    "                return_tensors='pt',\n",
    "                add_special_tokens=True)\n",
    "    input_ids = encoding['input_ids']\n",
    "    return input_ids\n",
    "\n",
    "for i in range(len(paragraph)):\n",
    "    paragraph[i]=embedding_text(paragraph[i])\n",
    "    print(paragraph[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "[[0.10953094]]\n",
      "[[0.05800227]]\n",
      "[[0.14370947]]\n",
      "[[0.11550281]]\n",
      "[[0.13474506]]\n",
      "di non sembrare troppo nervoso. lei alza² lo sguardo e mi regala² un sorriso cosa¬ caldo che sembrava sciogliere ogni ansia. da quel momento, le nostre vite iniziarono a intrecciarsi come i rami di quell'albero sotto cui ci eravamo incontrati. alessia era piena di passioni : amava dipingere tramonti, cantare canzoni sotto la piog\n",
      "[[0.14370947]]\n"
     ]
    }
   ],
   "source": [
    "user_question = 'piena di passioni'\n",
    "user_emb = embedding_text(user_question)\n",
    "print(user_emb.size())\n",
    "print(paragraph[0].size())\n",
    "\n",
    "max_match=0\n",
    "match_paragraph=[]\n",
    "for ele in paragraph:\n",
    "    print(cosine_similarity(user_emb,ele))\n",
    "    if cosine_similarity(user_emb,ele) > max_match:\n",
    "        \n",
    "        max_match = cosine_similarity(user_emb,ele)\n",
    "        match_paragraph=[ele,max_match]\n",
    "\n",
    "\n",
    "print(tokenizer.decode(match_paragraph[0][0], skip_special_tokens=True))\n",
    "print(match_paragraph[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
